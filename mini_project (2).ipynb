{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\navya\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: keras-ocr in c:\\users\\navya\\anaconda3\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: yolov5 in c:\\users\\navya\\anaconda3\\lib\\site-packages (7.0.13)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\navya\\anaconda3\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: transformers in c:\\users\\navya\\anaconda3\\lib\\site-packages (4.28.0)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\navya\\anaconda3\\lib\\site-packages (8.2.30)\n",
      "Requirement already satisfied: torch in c:\\users\\navya\\anaconda3\\lib\\site-packages (from timm) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\navya\\anaconda3\\lib\\site-packages (from timm) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\navya\\anaconda3\\lib\\site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\navya\\anaconda3\\lib\\site-packages (from timm) (0.17.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\navya\\anaconda3\\lib\\site-packages (from timm) (0.3.3)\n",
      "Requirement already satisfied: editdistance in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (0.8.1)\n",
      "Requirement already satisfied: efficientnet==1.0.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (1.0.0)\n",
      "Requirement already satisfied: essential_generators in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (1.0)\n",
      "Requirement already satisfied: fonttools in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (4.25.0)\n",
      "Requirement already satisfied: imgaug in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (1.3.0.post5)\n",
      "Requirement already satisfied: shapely in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (2.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (4.65.0)\n",
      "Requirement already satisfied: validators in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-ocr) (0.22.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from efficientnet==1.0.0->keras-ocr) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\navya\\anaconda3\\lib\\site-packages (from efficientnet==1.0.0->keras-ocr) (0.20.0)\n",
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (3.1.37)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (1.24.3)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (9.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (2.13.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (68.0.0)\n",
      "Requirement already satisfied: fire in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (0.6.0)\n",
      "Requirement already satisfied: boto3>=1.19.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (1.24.28)\n",
      "Requirement already satisfied: sahi>=0.11.10 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (0.11.16)\n",
      "Requirement already satisfied: roboflow>=0.2.29 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from yolov5) (1.1.32)\n",
      "Requirement already satisfied: filelock in c:\\users\\navya\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\navya\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=0.2.5 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from ultralytics) (0.2.8)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from boto3>=1.19.1->yolov5) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from boto3>=1.19.1->yolov5) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from boto3>=1.19.1->yolov5) (0.6.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from gitpython>=3.1.30->yolov5) (4.0.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\navya\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->yolov5) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->yolov5) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->yolov5) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->yolov5) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->yolov5) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->yolov5) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (4.0.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (4.8.0.74)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (1.16.0)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\navya\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5) (0.4.27)\n",
      "Requirement already satisfied: pybboxes==0.1.6 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from sahi>=0.11.10->yolov5) (0.1.6)\n",
      "Requirement already satisfied: terminaltables in c:\\users\\navya\\anaconda3\\lib\\site-packages (from sahi>=0.11.10->yolov5) (3.1.10)\n",
      "Requirement already satisfied: click in c:\\users\\navya\\anaconda3\\lib\\site-packages (from sahi>=0.11.10->yolov5) (8.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (1.57.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (3.4.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (4.21.12)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5) (0.38.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\navya\\anaconda3\\lib\\site-packages (from torch->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\navya\\anaconda3\\lib\\site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\navya\\anaconda3\\lib\\site-packages (from tqdm->keras-ocr) (0.4.6)\n",
      "Requirement already satisfied: termcolor in c:\\users\\navya\\anaconda3\\lib\\site-packages (from fire->yolov5) (2.3.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\navya\\anaconda3\\lib\\site-packages (from imgaug->keras-ocr) (2.26.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->yolov5) (1.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\navya\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.7.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->yolov5) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm keras-ocr yolov5 opencv-python transformers ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RHlMbkL2lYE4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\navya\\anaconda3\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from skimage import metrics\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from transformers import pipeline, AutoImageProcessor, AutoModelForDepthEstimation\n",
    "import torch\n",
    "import keras_ocr\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import math\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "eEiiox7OnKoD",
    "outputId": "50179712-f8f7-4e0b-e322-ea8d34795f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\navya\\anaconda3\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wUJPqVYfnME7"
   },
   "outputs": [],
   "source": [
    "# Function to create a CSV file with column names\n",
    "def create_csv_file(csv_filename):\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['id', 'timestamp', 'path', 'caption', 'depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8PnZNvxOnexj"
   },
   "outputs": [],
   "source": [
    "def capture_and_store_frames(csv_filename, frames_folder):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_frame = None\n",
    "    frame_count = 0  # Counter for captured frames\n",
    "\n",
    "    while frame_count < 10:  # Capture 10 frames\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save the frame\n",
    "        save_frame(frame, csv_filename, frames_folder)\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the camera\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sZKahY6Pniki"
   },
   "outputs": [],
   "source": [
    "def save_frame(frame, csv_filename, frames_folder):\n",
    "    # Generate unique ID for the frame\n",
    "    frame_id = str(uuid.uuid4())\n",
    "\n",
    "    # Timestamp of the frame\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Write frame to the frames folder with unique ID\n",
    "    frame_path = os.path.join(frames_folder, frame_id + '.jpg')\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "\n",
    "    # Write frame details to CSV file\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([frame_id, timestamp, frame_path])\n",
    "\n",
    "def is_similar(image1, image2, threshold=0.9):\n",
    "    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ssim_score = metrics.structural_similarity(image1_gray, image2_gray)\n",
    "    return ssim_score > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Yu_mYjJ8nmX3"
   },
   "outputs": [],
   "source": [
    "def generate_image_caption(image_path, processor, model):\n",
    "    # Load an image from local storage\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Preprocess the image\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate caption\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "    # Decode the generated caption\n",
    "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bRUrkvtY_0_k"
   },
   "outputs": [],
   "source": [
    "def detect_objects(image_path):\n",
    "    model_checkpoint = \"facebook/detr-resnet-50\"\n",
    "    object_detector = pipeline(\"object-detection\", model=model_checkpoint)\n",
    "    image = Image.open(image_path)\n",
    "    detections = object_detector(image)\n",
    "    results = []\n",
    "    for detection in detections:\n",
    "        box = detection['box']\n",
    "        label = detection['label']\n",
    "        score = detection['score']\n",
    "        results.append({\n",
    "            'object': label,\n",
    "            'score': score,\n",
    "            'coordinates': {\n",
    "                'xmin': box['xmin'],\n",
    "                'ymin': box['ymin'],\n",
    "                'xmax': box['xmax'],\n",
    "                'ymax': box['ymax']\n",
    "            }\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CFvOJx0Rnpke"
   },
   "outputs": [],
   "source": [
    "def estimate_depth(image_path):\n",
    "    # Load the depth estimation model\n",
    "    checkpoint = \"vinvino02/glpn-nyu\"\n",
    "    depth_estimator = pipeline(\"depth-estimation\", model=checkpoint)\n",
    "    image = Image.open(image_path)\n",
    "    predictions = depth_estimator(image)\n",
    "    img_depth = np.array(predictions[\"depth\"])\n",
    "\n",
    "    detected_objects = detect_objects(image_path)\n",
    "\n",
    "    # Estimate the depth map\n",
    "    depth_map = img_depth\n",
    "\n",
    "    # Analyze the depth within bounding boxes\n",
    "    analysis_results = []\n",
    "    for obj in detected_objects:\n",
    "        box = obj['coordinates']\n",
    "        xmin, ymin, xmax, ymax = int(box['xmin']), int(box['ymin']), int(box['xmax']), int(box['ymax'])\n",
    "\n",
    "        # Crop the depth map to the bounding box\n",
    "        depth_crop = depth_map[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        # Calculate the average depth in the bounding box\n",
    "        avg_depth = np.mean(depth_crop)\n",
    "\n",
    "        threshold = 100\n",
    "\n",
    "        # Determine if the object is near or far based on the threshold\n",
    "        if avg_depth < threshold:\n",
    "            distance = 'near'\n",
    "        else:\n",
    "            distance = 'far'\n",
    "\n",
    "        analysis_results.append({\n",
    "            'object': obj['object'],\n",
    "            'score': obj['score'],\n",
    "            'coordinates': obj['coordinates'],\n",
    "            'avg_depth': avg_depth,\n",
    "            'distance': distance\n",
    "        })\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PkvSAZxonz_R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def perform_ocr(image_path, ocr_pipeline):\\n    image = keras_ocr.tools.read(image_path)\\n    predictions = ocr_pipeline.recognize([image])[0]\\n    ocr_text = \" \".join([text for text, box in predictions])\\n    return ocr_text'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def perform_ocr(image_path, ocr_pipeline):\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    predictions = ocr_pipeline.recognize([image])[0]\n",
    "    ocr_text = \" \".join([text for text, box in predictions])\n",
    "    return ocr_text'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFP6O_Gcn24G",
    "outputId": "1773bdeb-fdda-433e-d49d-f1db4f443d60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "C:\\Users\\navya\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption response time for 3ba9d4d2-adc9-431b-b756-3bc9ab011852.jpg: 7.978343 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth estimation response time for 3ba9d4d2-adc9-431b-b756-3bc9ab011852.jpg: 24.187975 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_filename = 'frames_data.csv'\n",
    "    results_csv_filename = 'results_data.csv'\n",
    "    frames_folder = 'frames'\n",
    "\n",
    "    if not os.path.exists(frames_folder):\n",
    "        os.makedirs(frames_folder)\n",
    "\n",
    "    if not os.path.exists(csv_filename):\n",
    "        create_csv_file(csv_filename)\n",
    "\n",
    "    capture_and_store_frames(csv_filename, frames_folder)\n",
    "\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "    # Initialize OCR pipeline\n",
    "    #ocr_pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "    # Create results CSV file with column names\n",
    "    create_csv_file(results_csv_filename)\n",
    "\n",
    "    # Generate captions, depth estimations, and perform OCR for saved frames\n",
    "    for frame in os.listdir(frames_folder):\n",
    "        frame_path = os.path.join(frames_folder, frame)\n",
    "        caption = generate_image_caption(frame_path, processor, model)\n",
    "        depth = estimate_depth(frame_path)\n",
    "        #ocr_results = perform_ocr(frame_path, ocr_pipeline)\n",
    "        \n",
    "        # Measure caption generation time\n",
    "        start_time_caption = datetime.now()\n",
    "        caption = generate_image_caption(frame_path, processor, model)\n",
    "        end_time_caption = datetime.now()\n",
    "        caption_response_time = (end_time_caption - start_time_caption).total_seconds()\n",
    "        print(f\"Caption response time for {frame}: {caption_response_time} seconds\")\n",
    "        \n",
    "        # Measure depth estimation time\n",
    "        start_time_depth = datetime.now()\n",
    "        depth = estimate_depth(frame_path)\n",
    "        end_time_depth = datetime.now()\n",
    "        depth_response_time = (end_time_depth - start_time_depth).total_seconds()\n",
    "        print(f\"Depth estimation response time for {frame}: {depth_response_time} seconds\")\n",
    "\n",
    "        # Save results to the CSV file\n",
    "        with open(results_csv_filename, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([frame, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), frame_path, caption, depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
